# Masterarbeit-Code
Das Repository enthält den gesamten Code, der im Rahmen der Masterarbeit "Vergleichende Evaluation von Algorithmen zur zeitlichen Textklassifizierung mittels linguistisch motiviertem Feature Engineering" verwendet wurde. Die einzelnen Skripte sind geordnet nach ihrer Nutzung für das jeweilige Korpus in zwei Ordnern sortiert und beschriftet.

Die Skripte S1-S6 im Ordner Spiegel enthalten Code für das Preprocessing und Feature Engineering des deutschen Spiegel Korpus und mit den Skripten S7-S9 werden die Classifier traininert, wobei bei den Skripten S8 und S9 der Stemmer bzw. Lemmatizer vorgeschaltet ist. 

Das Skript S1 dient der Konvertierung der Spiegeldaten vom TSV-Format in das verarbeitbare CSV-Format. Mit dem Skript S2 wird den Datensets neben den zwei vorhandenen Spalten mit den N-Grammen und den N-Gramm-Häufigkeiten eine dritte Spalte für das Klassenlabel sowie das jeweilige Label hinzugefügt. Skript S3 entfernt ungewünschte Zeichen und Punktierungen. Mit dem Skript S4 werden die N-Gramme in einem ersten Durchlauf mit einer Stoppwortliste bearbeitet und anschließend je nach Definition (in Abschnitt 7 definierbar) 2-, 3-, 4- oder 5-Gramme aus dem Korpus gefiltert. In einem zweiten Durchlauf wird die Anwendung der Stoppwortliste auskommentiert (siehe Abschnitt 4 und 5) und die Herausfilterung der N-Gramme ohne die Anwendung der Liste durchgeführt. Zudem wird der Datenumfang des Korpus definiert, die N-Gramme in Kleinbuchstaben umgewandelt und die Spalte der N-Gramm-Häufigkeiten entfernt. Das Skript S5 dient der Lemmatisierung und dem PoS-Tagging der Textdaten mit dem Hanover-Tagger, wobei die Substantive bzw. Substantive und Adjektive ohne ihr Tagging herausgefiltert werden und aus den Daten ein neues Korpus generiert wird. Zudem werden leere Zeilen entfernt und die Korpusgröße definiert. Skript S6 wurde für die Zusammenführung der bis dahin einzeln vorliegenden Jahrzehnt-Datensets. Das Training der Classifier ohne vorheriges Stemming oder Lemmatisieren der generierten Feature Sets wird mit dem Skript S7 angestoßen. Hier befindet sich auch der Code für die Ausgabe der fehlerhaft klassifizierten Daten (siehe Abschnitt 84). Mit dem Skript S8 wird selbiges Training der Classifier durchgeführt, allerdings mit einem vorherigen Stemming der Daten und mit dem Skript S9 wird das Training mit einer vorherigen Lemmatisierung der Daten angestoßen.

Bei den Skripten NYT1-NYT13 im Ordner New York Times handelt es sich um Skripte, die im Rahmen des Teilprojektes mit dem englischen New York Times Korpus verwendet wurden. Die Skripte NYT1-NYT9 enthalten Code für das Preprocessing und Feature Engineering der Daten und die Skripte NYT10-NYT13 dienen dem Training der Classifier, wobei bei den Skripten NYT11-NYT13 jeweils Stemmer oder Lemmatizer vorgeschaltet sind. 

Zuerst wird das Skript NYT1 durchgeführt, mit dem alle Artikel aus den XML-Dokumenten innerhalb einer Ordnerstruktur herausgezogen und gesammelt in einer CSV-Datei gespeichert werden. Mit den beiden NYT2 Skripten werden einzelne ungewollte Inhalte unter den Artikeln der 80er und 2000er Datensets entfernt. Ebenso werden leere Zeilen und Punktierungen mit den Skripten NYT3 und NYT4 entfernt. Mit dem Skript NYT5 wird den Datensets neben der vorhandenen Spalte mit den Artikeln eine zweite Spalte für das Klassenlabel sowie das jeweilige Label hinzugefügt. Das Skript NYT7 dient der Erstellung von Datensets in drei verschiedenen Größen. Dabei wird jeweils einer der Abschnitte 3 bis 5 durchgeführt, die anderen beiden werden auskommentiert. Skript NYT8 wird für die Erstellung der N-Gramm Sets verwendet, wobei für die Erstellung jedes N-Gramm Sets einmal die in Abschnitt 4 und 5 verwendete Stoppwortliste angewendet wird und diese Abschnitte in einem zweiten Durchgang auskommentiert werden, um Datensets mit Stoppwörtern zu erstellen. Je nachdem, welches N-Gramm Set generiert werden soll, wird dies in Abschnitt 17 definiert. In den Abschnitten davor werden die 2-, 3-, 4- und 5-Gramme definiert. Das Skript NYT9 dient dem PoS-Tagging der Textdaten mit dem NLTK Tagger, wobei die Substantive bzw. Substantive und Adjektive herausgefiltert werden und aus den Daten ein neues Korpus generiert wird. Zudem werden leere Zeilen entfernt und die Korpusgröße definiert. Das Training der Classifier ohne vorheriges Stemming oder Lemmatisieren der generierten Feature Sets wird mit dem Skript NYT10 angestoßen. Hier befindet sich auch der Code für die Ausgabe der fehlerhaft klassifizierten Daten (siehe Abschnitt 84). Mit dem Skript NYT11 wird das Training mit einer vorherigen Lemmatisierung der Daten angestoßen und mit den Skripten NYT12 und NYT13 wird selbiges Training der Classifier durchgeführt, allerdings mit einem vorherigen Stemming der Daten mit dem Porter- bzw. dem Snowball Stemmer.

